{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dedee6b4",
   "metadata": {},
   "source": [
    "#### This project is about how to predict fit the candidate is based on their available information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a1b7b",
   "metadata": {},
   "source": [
    "### Importing Librariers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a960121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787cd403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \n",
       "0                       Houston, Texas         85  NaN  \n",
       "1                               Kanada      500+   NaN  \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                        Denton, Texas      500+   NaN  \n",
       "4                       İzmir, Türkiye      500+   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv(\"potential-talents - Aspiring human resources - seeking human resources.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bd1f441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data shape is (104, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"The data shape is {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44dfc520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104 entries, 0 to 103\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          104 non-null    int64  \n",
      " 1   job_title   104 non-null    object \n",
      " 2   location    104 non-null    object \n",
      " 3   connection  104 non-null    object \n",
      " 4   fit         0 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 4.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42e7730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The **Fit** column is targeted column soe we can drop it.\n",
    "df.drop(\"fit\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba3e5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  \n",
       "0                       Houston, Texas         85  \n",
       "1                               Kanada      500+   \n",
       "2  Raleigh-Durham, North Carolina Area         44  \n",
       "3                        Denton, Texas      500+   \n",
       "4                       İzmir, Türkiye      500+   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18cfb5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 104 unique value is id column\n",
      "There is 52 unique value is job_title column\n",
      "There is 41 unique value is location column\n",
      "There is 33 unique value is connection column\n"
     ]
    }
   ],
   "source": [
    "### Checking the numbers of unique value in each columns\n",
    "for col in df.columns:\n",
    "    print(f\"There is {df[col].nunique()} unique value is {col} column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57bfa306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicated row is: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of duplicated row is:\", df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d4d9998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate entries: 51\n"
     ]
    }
   ],
   "source": [
    "df_dup = df.drop([\"id\"], axis=1)\n",
    "print(\"Number of duplicate entries:\" , df_dup.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b3f20a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>HR Senior Specialist</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>500+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>Seeking Human Resources HRIS and Generalist Po...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>Student at Chapman University</td>\n",
       "      <td>Lake Forest, California</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>SVP, CHRO, Marketing &amp; Communications, CSR Off...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>500+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>Human Resources Coordinator at InterContinenta...</td>\n",
       "      <td>Atlanta, Georgia</td>\n",
       "      <td>500+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "0    1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1    2  Native English Teacher at EPIK (English Progra...   \n",
       "2    3              Aspiring Human Resources Professional   \n",
       "3    4             People Development Coordinator at Ryan   \n",
       "4    5    Advisory Board Member at Celal Bayar University   \n",
       "..  ..                                                ...   \n",
       "60  61                               HR Senior Specialist   \n",
       "61  62  Seeking Human Resources HRIS and Generalist Po...   \n",
       "62  63                      Student at Chapman University   \n",
       "63  64  SVP, CHRO, Marketing & Communications, CSR Off...   \n",
       "64  65  Human Resources Coordinator at InterContinenta...   \n",
       "\n",
       "                               location connection  \n",
       "0                        Houston, Texas         85  \n",
       "1                                Kanada      500+   \n",
       "2   Raleigh-Durham, North Carolina Area         44  \n",
       "3                         Denton, Texas      500+   \n",
       "4                        İzmir, Türkiye      500+   \n",
       "..                                  ...        ...  \n",
       "60               San Francisco Bay Area      500+   \n",
       "61            Greater Philadelphia Area      500+   \n",
       "62              Lake Forest, California          2  \n",
       "63                  Houston, Texas Area      500+   \n",
       "64                     Atlanta, Georgia      500+   \n",
       "\n",
       "[65 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df_dup.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd8c16f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape fo non-duplicated dataframe: (53, 4)\n"
     ]
    }
   ],
   "source": [
    "## Dropping the duplicated rows\n",
    "df_dup =df_dup.drop_duplicates()\n",
    "df =pd.concat([df[\"id\"], df_dup], axis=1).dropna(axis=0)\n",
    "print(\"Shape fo non-duplicated dataframe:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a5985d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44e4b26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aspiring Human Resources Professional                                                                                    2\n",
       "2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional                 1\n",
       "Lead Official at Western Illinois University                                                                             1\n",
       "Senior Human Resources Business Partner at Heil Environmental                                                            1\n",
       "Aspiring Human Resources Professional | An energetic and Team-Focused Leader                                             1\n",
       "HR Manager at Endemol Shine North America                                                                                1\n",
       "Human Resources professional for the world leader in GIS software                                                        1\n",
       "RRP Brand Portfolio Executive at JTI (Japan Tobacco International)                                                       1\n",
       "Information Systems Specialist and Programmer with a love for data and organization.                                     1\n",
       "Bachelor of Science in Biology from Victoria University of Wellington                                                    1\n",
       "Human Resources Management Major                                                                                         1\n",
       "Director Human Resources  at EY                                                                                          1\n",
       "Undergraduate Research Assistant at Styczynski Lab                                                                       1\n",
       "Seeking employment opportunities within Customer Service or Patient Care                                                 1\n",
       "Liberal Arts Major. Aspiring Human Resources Analyst.                                                                    1\n",
       "Admissions Representative at Community medical center long beach                                                         1\n",
       "Seeking Human  Resources Opportunities. Open to travel and relocation.                                                   1\n",
       "Student at Westfield State University                                                                                    1\n",
       "Student at Indiana University Kokomo - Business Management - \\nRetail Manager at Delphi Hardware and Paint               1\n",
       "Student                                                                                                                  1\n",
       "Seeking Human Resources Position                                                                                         1\n",
       "Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis    1\n",
       "Human Resources Generalist at Loparex                                                                                    1\n",
       "Business Intelligence and Analytics at Travelers                                                                         1\n",
       "Always set them up for Success                                                                                           1\n",
       "Junior MES Engineer| Information Systems                                                                                 1\n",
       "Human Resources Generalist at Schwan's                                                                                   1\n",
       "Native English Teacher at EPIK (English Program in Korea)                                                                1\n",
       "Seeking Human Resources Opportunities                                                                                    1\n",
       "People Development Coordinator at Ryan                                                                                   1\n",
       "Advisory Board Member at Celal Bayar University                                                                          1\n",
       "Aspiring Human Resources Specialist                                                                                      1\n",
       "Student at Humber College and Aspiring Human Resources Generalist                                                        1\n",
       "HR Senior Specialist                                                                                                     1\n",
       "Seeking Human Resources HRIS and Generalist Positions                                                                    1\n",
       "Student at Chapman University                                                                                            1\n",
       "SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR              1\n",
       "Human Resources Coordinator at InterContinental Buckhead Atlanta                                                         1\n",
       "Aspiring Human Resources Management student seeking an internship                                                        1\n",
       "Experienced Retail Manager and aspiring Human Resources Professional                                                     1\n",
       "Human Resources|\\nConflict Management|\\nPolicies & Procedures|Talent Management|Benefits & Compensation                  1\n",
       "Human Resources, Staffing and Recruiting Professional                                                                    1\n",
       "Human Resources Specialist at Luxottica                                                                                  1\n",
       "Director of Human Resources North America, Groupe Beneteau                                                               1\n",
       "Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources.                           1\n",
       "Human Resources Generalist at ScottMadden, Inc.                                                                          1\n",
       "Business Management Major and Aspiring Human Resources Manager                                                           1\n",
       "Aspiring Human Resources Manager, seeking internship in Human Resources.                                                 1\n",
       "Human Resources Professional                                                                                             1\n",
       "Nortia Staffing is seeking Human Resources, Payroll & Administrative Professionals!!  (408) 709-2621                     1\n",
       "Aspiring Human Resources Professional | Passionate about helping to create an inclusive and engaging work environment    1\n",
       "Director Of Administration at Excellence Logging                                                                         1\n",
       "Name: job_title, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.job_title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a5f3d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4d63ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total words 221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Human', 34),\n",
       " ('Resources', 29),\n",
       " ('at', 22),\n",
       " ('and', 13),\n",
       " ('Aspiring', 11),\n",
       " ('|', 10),\n",
       " ('Professional', 7),\n",
       " ('in', 6),\n",
       " ('University', 6),\n",
       " ('Seeking', 6),\n",
       " ('Business', 5),\n",
       " ('Student', 5),\n",
       " ('Generalist', 5),\n",
       " ('Manager', 5),\n",
       " ('of', 4),\n",
       " ('Specialist', 4),\n",
       " ('&', 4),\n",
       " ('Management', 4),\n",
       " ('seeking', 4),\n",
       " ('', 4),\n",
       " ('an', 3),\n",
       " ('Director', 3),\n",
       " ('for', 3),\n",
       " ('College', 2),\n",
       " ('aspiring', 2),\n",
       " ('professional', 2),\n",
       " ('Coordinator', 2),\n",
       " ('HR', 2),\n",
       " ('Senior', 2),\n",
       " ('internship', 2),\n",
       " ('Resources,', 2),\n",
       " ('Staffing', 2),\n",
       " ('North', 2),\n",
       " ('a', 2),\n",
       " ('Resources.', 2),\n",
       " ('Major', 2),\n",
       " ('to', 2),\n",
       " ('Information', 2),\n",
       " ('Systems', 2),\n",
       " ('-', 2),\n",
       " ('Position', 2),\n",
       " ('2019', 1),\n",
       " ('C.T.', 1),\n",
       " ('Bauer', 1),\n",
       " ('Graduate', 1),\n",
       " ('(Magna', 1),\n",
       " ('Cum', 1),\n",
       " ('Laude)', 1),\n",
       " ('Native', 1),\n",
       " ('English', 1),\n",
       " ('Teacher', 1),\n",
       " ('EPIK', 1),\n",
       " ('(English', 1),\n",
       " ('Program', 1),\n",
       " ('Korea)', 1),\n",
       " ('People', 1),\n",
       " ('Development', 1),\n",
       " ('Ryan', 1),\n",
       " ('Advisory', 1),\n",
       " ('Board', 1),\n",
       " ('Member', 1),\n",
       " ('Celal', 1),\n",
       " ('Bayar', 1),\n",
       " ('Humber', 1),\n",
       " ('HRIS', 1),\n",
       " ('Positions', 1),\n",
       " ('Chapman', 1),\n",
       " ('SVP,', 1),\n",
       " ('CHRO,', 1),\n",
       " ('Marketing', 1),\n",
       " ('Communications,', 1),\n",
       " ('CSR', 1),\n",
       " ('Officer', 1),\n",
       " ('ENGIE', 1),\n",
       " ('Houston', 1),\n",
       " ('The', 1),\n",
       " ('Woodlands', 1),\n",
       " ('Energy', 1),\n",
       " ('GPHR', 1),\n",
       " ('SPHR', 1),\n",
       " ('InterContinental', 1),\n",
       " ('Buckhead', 1),\n",
       " ('Atlanta', 1),\n",
       " ('student', 1),\n",
       " ('Opportunities', 1),\n",
       " ('Experienced', 1),\n",
       " ('Retail', 1),\n",
       " ('Recruiting', 1),\n",
       " ('Luxottica', 1),\n",
       " ('America,', 1),\n",
       " ('Groupe', 1),\n",
       " ('Beneteau', 1),\n",
       " ('Retired', 1),\n",
       " ('Army', 1),\n",
       " ('National', 1),\n",
       " ('Guard', 1),\n",
       " ('Recruiter,', 1),\n",
       " ('office', 1),\n",
       " ('manager,', 1),\n",
       " ('position', 1),\n",
       " ('ScottMadden,', 1),\n",
       " ('Inc.', 1),\n",
       " ('Manager,', 1),\n",
       " ('Nortia', 1),\n",
       " ('is', 1),\n",
       " ('Payroll', 1),\n",
       " ('Administrative', 1),\n",
       " ('Professionals!!', 1),\n",
       " ('(408)', 1),\n",
       " ('709-2621', 1),\n",
       " ('Passionate', 1),\n",
       " ('about', 1),\n",
       " ('helping', 1),\n",
       " ('create', 1),\n",
       " ('inclusive', 1),\n",
       " ('engaging', 1),\n",
       " ('work', 1),\n",
       " ('environment', 1),\n",
       " ('Resources|\\nConflict', 1),\n",
       " ('Management|\\nPolicies', 1),\n",
       " ('Procedures|Talent', 1),\n",
       " ('Management|Benefits', 1),\n",
       " ('Compensation', 1),\n",
       " (\"Schwan's\", 1),\n",
       " ('Liberal', 1),\n",
       " ('Arts', 1),\n",
       " ('Major.', 1),\n",
       " ('Analyst.', 1),\n",
       " ('Junior', 1),\n",
       " ('MES', 1),\n",
       " ('Engineer|', 1),\n",
       " ('Partner', 1),\n",
       " ('Heil', 1),\n",
       " ('Environmental', 1),\n",
       " ('An', 1),\n",
       " ('energetic', 1),\n",
       " ('Team-Focused', 1),\n",
       " ('Leader', 1),\n",
       " ('Endemol', 1),\n",
       " ('Shine', 1),\n",
       " ('America', 1),\n",
       " ('the', 1),\n",
       " ('world', 1),\n",
       " ('leader', 1),\n",
       " ('GIS', 1),\n",
       " ('software', 1),\n",
       " ('RRP', 1),\n",
       " ('Brand', 1),\n",
       " ('Portfolio', 1),\n",
       " ('Executive', 1),\n",
       " ('JTI', 1),\n",
       " ('(Japan', 1),\n",
       " ('Tobacco', 1),\n",
       " ('International)', 1),\n",
       " ('Programmer', 1),\n",
       " ('with', 1),\n",
       " ('love', 1),\n",
       " ('data', 1),\n",
       " ('organization.', 1),\n",
       " ('Bachelor', 1),\n",
       " ('Science', 1),\n",
       " ('Biology', 1),\n",
       " ('from', 1),\n",
       " ('Victoria', 1),\n",
       " ('Wellington', 1),\n",
       " ('EY', 1),\n",
       " ('Undergraduate', 1),\n",
       " ('Research', 1),\n",
       " ('Assistant', 1),\n",
       " ('Styczynski', 1),\n",
       " ('Lab', 1),\n",
       " ('Lead', 1),\n",
       " ('Official', 1),\n",
       " ('Western', 1),\n",
       " ('Illinois', 1),\n",
       " ('employment', 1),\n",
       " ('opportunities', 1),\n",
       " ('within', 1),\n",
       " ('Customer', 1),\n",
       " ('Service', 1),\n",
       " ('or', 1),\n",
       " ('Patient', 1),\n",
       " ('Care', 1),\n",
       " ('Admissions', 1),\n",
       " ('Representative', 1),\n",
       " ('Community', 1),\n",
       " ('medical', 1),\n",
       " ('center', 1),\n",
       " ('long', 1),\n",
       " ('beach', 1),\n",
       " ('Opportunities.', 1),\n",
       " ('Open', 1),\n",
       " ('travel', 1),\n",
       " ('relocation.', 1),\n",
       " ('Westfield', 1),\n",
       " ('State', 1),\n",
       " ('Indiana', 1),\n",
       " ('Kokomo', 1),\n",
       " ('\\nRetail', 1),\n",
       " ('Delphi', 1),\n",
       " ('Hardware', 1),\n",
       " ('Paint', 1),\n",
       " ('Graduating', 1),\n",
       " ('May', 1),\n",
       " ('2020', 1),\n",
       " ('Entry-Level', 1),\n",
       " ('St.', 1),\n",
       " ('Louis', 1),\n",
       " ('Loparex', 1),\n",
       " ('Intelligence', 1),\n",
       " ('Analytics', 1),\n",
       " ('Travelers', 1),\n",
       " ('Always', 1),\n",
       " ('set', 1),\n",
       " ('them', 1),\n",
       " ('up', 1),\n",
       " ('Success', 1),\n",
       " ('Of', 1),\n",
       " ('Administration', 1),\n",
       " ('Excellence', 1),\n",
       " ('Logging', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking most frequent words..\n",
    "words_counts = Counter()\n",
    "for i in range(len(df)):\n",
    "    for word in df.job_title[i].split(\" \"):\n",
    "        words_counts[word] += 1\n",
    "\n",
    "print(\"Number of total words\" , len(words_counts))\n",
    "words_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24fe3443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Houston, Texas Area                    4\n",
       "Raleigh-Durham, North Carolina Area    3\n",
       "Greater New York City Area             3\n",
       "Austin, Texas Area                     2\n",
       "Amerika Birleşik Devletleri            2\n",
       "Kanada                                 2\n",
       "Greater Philadelphia Area              2\n",
       "Greater Atlanta Area                   2\n",
       "Torrance, California                   1\n",
       "Highland, California                   1\n",
       "Gaithersburg, Maryland                 1\n",
       "Baltimore, Maryland                    1\n",
       "Milpitas, California                   1\n",
       "Greater Chicago Area                   1\n",
       "Houston, Texas                         1\n",
       "Long Beach, California                 1\n",
       "Chattanooga, Tennessee Area            1\n",
       "Bridgewater, Massachusetts             1\n",
       "Lafayette, Indiana                     1\n",
       "Kokomo, Indiana Area                   1\n",
       "Las Vegas, Nevada Area                 1\n",
       "Cape Girardeau, Missouri               1\n",
       "Greater Los Angeles Area               1\n",
       "Los Angeles, California                1\n",
       "Dallas/Fort Worth Area                 1\n",
       "Myrtle Beach, South Carolina Area      1\n",
       "Baton Rouge, Louisiana Area            1\n",
       "New York, New York                     1\n",
       "San Jose, California                   1\n",
       "Greater Boston Area                    1\n",
       "Monroe, Louisiana Area                 1\n",
       "Virginia Beach, Virginia               1\n",
       "Greater Grand Rapids, Michigan Area    1\n",
       "Jackson, Mississippi Area              1\n",
       "Chicago, Illinois                      1\n",
       "Atlanta, Georgia                       1\n",
       "Lake Forest, California                1\n",
       "San Francisco Bay Area                 1\n",
       "İzmir, Türkiye                         1\n",
       "Denton, Texas                          1\n",
       "Katy, Texas                            1\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.location.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc9eea6",
   "metadata": {},
   "source": [
    "### Cleaning the data \n",
    " \n",
    "    * Removing special character \n",
    "    * Writting the text in lower case\n",
    "    * Removing stopwords and applying lemmatization\n",
    "    \n",
    "\n",
    "**Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma .**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c879123",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing special character \n",
    "df = df.replace({'location' : { \"[\\'!#)$%&(*+-./:;<=>?@[\\]^_`{|}~\\n]\" : \" \"}}, regex=True)\n",
    "df = df.replace({'connection' : { \"[\\'!#)$%&(*+-./:;<=>?@[\\]^_`{|}~\\n]\" : \" \"}}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6569e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston  Texas</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh Durham  North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton  Texas</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir  Türkiye</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  \n",
       "0                       Houston  Texas         85  \n",
       "1                               Kanada      500    \n",
       "2  Raleigh Durham  North Carolina Area         44  \n",
       "3                        Denton  Texas      500    \n",
       "4                       İzmir  Türkiye      500    "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c569804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 c.t. bauer college of business graduate (...</td>\n",
       "      <td>houston  texas</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>native english teacher at epik (english progra...</td>\n",
       "      <td>kanada</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>raleigh durham  north carolina area</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>people development coordinator at ryan</td>\n",
       "      <td>denton  texas</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>advisory board member at celal bayar university</td>\n",
       "      <td>i̇zmir  türkiye</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 c.t. bauer college of business graduate (...   \n",
       "1   2  native english teacher at epik (english progra...   \n",
       "2   3              aspiring human resources professional   \n",
       "3   4             people development coordinator at ryan   \n",
       "4   5    advisory board member at celal bayar university   \n",
       "\n",
       "                              location connection  \n",
       "0                       houston  texas         85  \n",
       "1                               kanada      500    \n",
       "2  raleigh durham  north carolina area         44  \n",
       "3                        denton  texas      500    \n",
       "4                      i̇zmir  türkiye      500    "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"job_title\"] =df[\"job_title\"].str.lower()\n",
    "df[\"location\"]=df[\"location\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48860d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ef175d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing stopwords and lemmatization \n",
    "\n",
    "def cleaning(df, col):\n",
    "    stop_words =set(stopwords.words(\"english\"))\n",
    "    for i in range(len(df)):\n",
    "        word_token =word_tokenize(df[col][i])\n",
    "        tokens_without_sw = [w for w in word_token if w not in stop_words]\n",
    "        lemmatized_sentence = []\n",
    "        for word in tokens_without_sw:\n",
    "            lemmatized_sentence.append(WordNetLemmatizer().lemmatize(word))\n",
    "        df[col][i] =TreebankWordDetokenizer().detokenize(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bdfef81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job title before removing stopwords:\n",
      " 0    2019 c.t. bauer college of business graduate (...\n",
      "Name: job_title, dtype: object\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Job title after removing stopwords:\n",
      " 0    2019 c.t . bauer college business graduate (ma...\n",
      "Name: job_title, dtype: object\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 c.t . bauer college business graduate (ma...</td>\n",
       "      <td>houston  texas</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>native english teacher epik (english program k...</td>\n",
       "      <td>kanada</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aspiring human resource professional</td>\n",
       "      <td>raleigh durham  north carolina area</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "      <td>denton  texas</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "      <td>i̇zmir  türkiye</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 c.t . bauer college business graduate (ma...   \n",
       "1   2  native english teacher epik (english program k...   \n",
       "2   3               aspiring human resource professional   \n",
       "3   4                people development coordinator ryan   \n",
       "4   5       advisory board member celal bayar university   \n",
       "\n",
       "                              location connection  \n",
       "0                       houston  texas         85  \n",
       "1                               kanada      500    \n",
       "2  raleigh durham  north carolina area         44  \n",
       "3                        denton  texas      500    \n",
       "4                      i̇zmir  türkiye      500    "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Job title before removing stopwords:\\n\", df.job_title.head(1))\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Removing stop words\n",
    "cleaning(df, \"job_title\")\n",
    "\n",
    "print(\"Job title after removing stopwords:\\n\", df.job_title.head(1))\n",
    "print(\"-\"*100)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ceadb410",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace the abbreviation with their description\n",
    "df = df.replace({'job_title' : { 'chro' : 'chief human resources officer', 'svp' : 'senior vice president'\n",
    "        ,'gphr' : 'global professional in human resources','hris' : 'human resources management system'\n",
    "        , 'csr' : 'corporate social responsibility', 'sphr' : 'strategic and policy-making certification'\n",
    "        , 'hr' : 'human resources', \"[\\'!#)$%&(*+-./:;<=>?@[\\]^_`{|}~\\n]\" : \"\", r'[0-9]' : '', 'epik' : 'tech'\n",
    "        , 'styczynski lab' : 'tech', 'gi' : 'tech', \"schwan's\" : 'tech', 'ryan' : 'not tech'\n",
    "        , 'engine' : 'not tech', 'buckhead atlanta' : 'not tech', 'loparex' : 'not tech', 'delphi Hardware' : 'not tech'\n",
    "        , \"jti\" : 'not tech', 'traveler' : 'not tech', 'luxottica' : 'not tech'\n",
    "        , 'beneteau' : 'not tech', 'scottMadden' : 'not tech', 'ey' : 'not tech', 'endemol' : 'not tech'\n",
    "        , 'nortia staffing' : 'not tech', 'heil environmental' : 'not tech', 'excellence logging' : 'not tech'}}\n",
    "        , regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9895a730",
   "metadata": {},
   "source": [
    "#### Word Embedding Techniques\n",
    "\n",
    "I will be using 4 different strategies to find the similarties betwen the targeted sentences and each job title as follows\n",
    "\n",
    " 1. **TF-IDF**(term frequency-inverse document frequency) is a statistical measure that evaluates how relevant a word is to a document in a collection of documents.\n",
    " \n",
    "    \n",
    "  2. **GloVe** stands for global vectors for word representation. It is used for generating word embeddings by aggregating global word-word co-occurrence matrix from a corpus. The resulting embeddings show interesting linear substructures of the word in vector space.\n",
    "    \n",
    "   \n",
    "   3. **Word2Vec** is a technique which produces word embeddings for better word representation. We can also say it consists of models for generating word embedding which are shallow two layer neural networks having one input layer, one hidden layer and one output layer.\n",
    "    \n",
    "   \n",
    "   4. **BERT** It is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5882c10",
   "metadata": {},
   "source": [
    "### 1. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ef5b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed548d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique features:  167\n",
      "First 5 features:  ['administration', 'administrative', 'admission', 'advisory', 'always']\n",
      "Shape of Tfidf Vector:  (53, 167)\n"
     ]
    }
   ],
   "source": [
    "## Convert hob titles column into a list\n",
    "job_title_list =list(df[\"job_title\"])\n",
    "\n",
    "# Vectorize job_title_list\n",
    "vectorizer =TfidfVectorizer().fit(job_title_list)\n",
    "X =vectorizer.transform(job_title_list)\n",
    "\n",
    "# Get feature names in all the documents\n",
    "feature_names =vectorizer.get_feature_names()\n",
    "print(\"Number of unique features: \", len(feature_names))\n",
    "print(\"First 5 features: \", feature_names[:5])\n",
    "\n",
    "# convert job titles into array\n",
    "tfidf_vector =X.toarray()\n",
    "print(\"Shape of Tfidf Vector: \", tfidf_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec1c216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating the similarity\n",
    "def similarity(phrase, column_name):\n",
    "    # convert search phrase into a vectors\n",
    "    X = vectorizer.transform(phrase)\n",
    "    X_vectors = X.toarray()\n",
    "    print(\"Shape of search phrase vector:\", X_vectors.shape)\n",
    "    \n",
    "    # calculate Tfidf cosine similarity \n",
    "    sim_score_list = []\n",
    "    for x in range(len(df)):\n",
    "        sim_score_list.append(1 - cosine(tfidf_vector[x], X_vectors))\n",
    "        \n",
    "    df[column_name] =sim_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98844067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searched prhase\n",
    "phrases =pd.DataFrame({\"phrase\":[\"aspiring human resources\"]})\n",
    "cleaning(phrases, \"phrase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "beef36cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of search phrase vector: (1, 167)\n"
     ]
    }
   ],
   "source": [
    "similarity([phrases.phrase[0]], \"TF-IDF_fit_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa29fcf0",
   "metadata": {},
   "source": [
    "**Let's see the top and lowest matching title job rows with the phrase (aspiring human resources).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b919c89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>TF-IDF_fit_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aspiring human resource professional</td>\n",
       "      <td>raleigh durham  north carolina area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.781184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>97</td>\n",
       "      <td>aspiring human resource professional</td>\n",
       "      <td>kokomo  indiana area</td>\n",
       "      <td>71</td>\n",
       "      <td>0.781184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>aspiring human resource specialist</td>\n",
       "      <td>greater new york city area</td>\n",
       "      <td>1</td>\n",
       "      <td>0.679890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>73</td>\n",
       "      <td>aspiring human resource manager seeking intern...</td>\n",
       "      <td>houston  texas area</td>\n",
       "      <td>7</td>\n",
       "      <td>0.618600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>aspiring human resource management student see...</td>\n",
       "      <td>houston  texas area</td>\n",
       "      <td>500</td>\n",
       "      <td>0.442293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "2    3               aspiring human resource professional   \n",
       "45  97               aspiring human resource professional   \n",
       "5    6                 aspiring human resource specialist   \n",
       "21  73  aspiring human resource manager seeking intern...   \n",
       "12  27  aspiring human resource management student see...   \n",
       "\n",
       "                               location connection  TF-IDF_fit_score  \n",
       "2   raleigh durham  north carolina area         44          0.781184  \n",
       "45                 kokomo  indiana area         71          0.781184  \n",
       "5            greater new york city area          1          0.679890  \n",
       "21                  houston  texas area          7          0.618600  \n",
       "12                  houston  texas area      500            0.442293  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by =\"TF-IDF_fit_score\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "448d226d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>TF-IDF_fit_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>86</td>\n",
       "      <td>information system specialist programmer love ...</td>\n",
       "      <td>gaithersburg  maryland</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>85</td>\n",
       "      <td>rrp brand portfolio executive not tech japan t...</td>\n",
       "      <td>greater philadelphia area</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>80</td>\n",
       "      <td>junior me entechneer information system</td>\n",
       "      <td>myrtle beach  south carolina area</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>native english teacher tech english program korea</td>\n",
       "      <td>kanada</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>104</td>\n",
       "      <td>director administration excellence logtechng</td>\n",
       "      <td>katy  texas</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                          job_title  \\\n",
       "34   86  information system specialist programmer love ...   \n",
       "33   85  rrp brand portfolio executive not tech japan t...   \n",
       "28   80            junior me entechneer information system   \n",
       "1     2  native english teacher tech english program korea   \n",
       "52  104       director administration excellence logtechng   \n",
       "\n",
       "                             location connection  TF-IDF_fit_score  \n",
       "34             gaithersburg  maryland          4               0.0  \n",
       "33          greater philadelphia area      500                 0.0  \n",
       "28  myrtle beach  south carolina area         52               0.0  \n",
       "1                              kanada      500                 0.0  \n",
       "52                        katy  texas      500                 0.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by =\"TF-IDF_fit_score\", ascending=False).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578d6e77",
   "metadata": {},
   "source": [
    "### 2. GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bb9c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wget\n",
    "#import wget\n",
    "#wget.download('http://nlp.stanford.edu/data/glove.6B.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e1e275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import zipfile as zf\n",
    "#files = zf.ZipFile(\"glove.6B.zip\", 'r')\n",
    "#files.extractall('GloVe')\n",
    "#files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d180198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "\n",
    "# Create temp file and save converted embedding into it\n",
    "target_file = get_tmpfile(\"word2vec.6B.50d.txt\")\n",
    "glove2word2vec(\"GloVe/glove.6B.50d.txt\", target_file)\n",
    "\n",
    "# Load the converetd embedding into memory\n",
    "glove_model = KeyedVectors.load_word2vec_format(target_file)\n",
    "\n",
    "# Save as binary data\n",
    "glove_model.save_word2vec_format('word2vec.6B.50d.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ad279d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_token_vectors(sentence, model, sentence_vector_list, vector_dimensions):\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    filtered_words = [w for w in word_tokens if w in model]\n",
    "    for j in range(len(word_tokens)):\n",
    "        if word_tokens[j] in filtered_words:\n",
    "            token_vector = model[word_tokens[j]]\n",
    "        else:\n",
    "            token_vector = np.zeros(vector_dimensions)\n",
    "        sentence_vector_list.append(token_vector)\n",
    "    \n",
    "    return sentence_vector_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bae759b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fitt_score(df, col, model, vector_dimensions, phrase, fitt_col_name):\n",
    "    # Vectorize job title using the model\n",
    "    model_vectors = []\n",
    "    for i in range(len(df)):\n",
    "        model_sentence_vector = []\n",
    "        doc_token_vectors(df[col][i], model, model_sentence_vector, vector_dimensions)\n",
    "        model_vectors.append(model_sentence_vector)\n",
    "\n",
    "    print('model vectors shape', np.shape(model_vectors))\n",
    "    # Vectorize searched phrase using the model\n",
    "    model_search_phrase_vector = []\n",
    "    doc_token_vectors(phrase, model, model_search_phrase_vector, vector_dimensions)\n",
    "    print('model search phrase vector shape', np.shape(model_search_phrase_vector))\n",
    "\n",
    "    # Calculate cosine similarity between searched phrase and job title\n",
    "    model_similarity =[]\n",
    "    for i in range(len(df)):\n",
    "        sim_score = 1 - cosine(np.mean(model_vectors[i], axis = 0), np.mean(model_search_phrase_vector, axis =0))\n",
    "        model_similarity.append(sim_score)\n",
    "\n",
    "    # Add model similarity score to the pt dataframe\n",
    "    df[fitt_col_name] = model_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2d27965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model vectors shape (53,)\n",
      "model search phrase vector shape (3, 50)\n"
     ]
    }
   ],
   "source": [
    "model_fitt_score(df, 'job_title', glove_model, 50, phrases.phrase[0], 'GloVe_fit_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "180a5247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>TF-IDF_fit_score</th>\n",
       "      <th>GloVe_fit_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>aspiring human resource specialist</td>\n",
       "      <td>greater new york city area</td>\n",
       "      <td>1</td>\n",
       "      <td>0.679890</td>\n",
       "      <td>0.969614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aspiring human resource professional</td>\n",
       "      <td>raleigh durham  north carolina area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.781184</td>\n",
       "      <td>0.958512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>97</td>\n",
       "      <td>aspiring human resource professional</td>\n",
       "      <td>kokomo  indiana area</td>\n",
       "      <td>71</td>\n",
       "      <td>0.781184</td>\n",
       "      <td>0.958512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>73</td>\n",
       "      <td>aspiring human resource manager seeking intern...</td>\n",
       "      <td>houston  texas area</td>\n",
       "      <td>7</td>\n",
       "      <td>0.618600</td>\n",
       "      <td>0.934672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>74</td>\n",
       "      <td>human resource professional</td>\n",
       "      <td>greater boston area</td>\n",
       "      <td>16</td>\n",
       "      <td>0.421758</td>\n",
       "      <td>0.933199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "5    6                 aspiring human resource specialist   \n",
       "2    3               aspiring human resource professional   \n",
       "45  97               aspiring human resource professional   \n",
       "21  73  aspiring human resource manager seeking intern...   \n",
       "22  74                        human resource professional   \n",
       "\n",
       "                               location connection  TF-IDF_fit_score  \\\n",
       "5            greater new york city area          1          0.679890   \n",
       "2   raleigh durham  north carolina area         44          0.781184   \n",
       "45                 kokomo  indiana area         71          0.781184   \n",
       "21                  houston  texas area          7          0.618600   \n",
       "22                  greater boston area         16          0.421758   \n",
       "\n",
       "    GloVe_fit_score  \n",
       "5          0.969614  \n",
       "2          0.958512  \n",
       "45         0.958512  \n",
       "21         0.934672  \n",
       "22         0.933199  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"GloVe_fit_score\", ascending =False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa54b67",
   "metadata": {},
   "source": [
    "### 3.Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e485c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleNews_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "373cfb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model vectors shape (53,)\n",
      "model search phrase vector shape (3, 300)\n"
     ]
    }
   ],
   "source": [
    "model_fitt_score(df, 'job_title', GoogleNews_model, 300, phrases.phrase[0], 'GoogleNews_fit_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ab0862e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>TF-IDF_fit_score</th>\n",
       "      <th>GloVe_fit_score</th>\n",
       "      <th>GoogleNews_fit_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>97</td>\n",
       "      <td>aspiring human resource professional</td>\n",
       "      <td>kokomo  indiana area</td>\n",
       "      <td>71</td>\n",
       "      <td>0.781184</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>0.950395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aspiring human resource professional</td>\n",
       "      <td>raleigh durham  north carolina area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.781184</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>0.950395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>aspiring human resource specialist</td>\n",
       "      <td>greater new york city area</td>\n",
       "      <td>1</td>\n",
       "      <td>0.679890</td>\n",
       "      <td>0.969614</td>\n",
       "      <td>0.912262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>73</td>\n",
       "      <td>aspiring human resource manager seeking intern...</td>\n",
       "      <td>houston  texas area</td>\n",
       "      <td>7</td>\n",
       "      <td>0.618600</td>\n",
       "      <td>0.934672</td>\n",
       "      <td>0.875945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>74</td>\n",
       "      <td>human resource professional</td>\n",
       "      <td>greater boston area</td>\n",
       "      <td>16</td>\n",
       "      <td>0.421758</td>\n",
       "      <td>0.933199</td>\n",
       "      <td>0.874494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "45  97               aspiring human resource professional   \n",
       "2    3               aspiring human resource professional   \n",
       "5    6                 aspiring human resource specialist   \n",
       "21  73  aspiring human resource manager seeking intern...   \n",
       "22  74                        human resource professional   \n",
       "\n",
       "                               location connection  TF-IDF_fit_score  \\\n",
       "45                 kokomo  indiana area         71          0.781184   \n",
       "2   raleigh durham  north carolina area         44          0.781184   \n",
       "5            greater new york city area          1          0.679890   \n",
       "21                  houston  texas area          7          0.618600   \n",
       "22                  greater boston area         16          0.421758   \n",
       "\n",
       "    GloVe_fit_score  GoogleNews_fit_score  \n",
       "45         0.958512              0.950395  \n",
       "2          0.958512              0.950395  \n",
       "5          0.969614              0.912262  \n",
       "21         0.934672              0.875945  \n",
       "22         0.933199              0.874494  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by ='GoogleNews_fit_score', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8a5de6",
   "metadata": {},
   "source": [
    "## 4. BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "955f8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "206fe5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abadda05a96a45fd98781581f7ca9c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1ed2a55ac6484b97a63781b9754daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e533e0b846ec4c578c5c34e579cd04b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f02645975a4c5db8cd8a3e93b437d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b20cd241b84bfcbc8cd523566c8234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eabdbc6fa341d5b4877ed14f858271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da9e13c170947559d79bd08be6f811f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ebc2951b5b4554a24b270b31212233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda053501e8d4c25a140384d31270b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37658c481c548f2a58555cb1db2fe18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b834fdcdd0874cb5a3d386c848216713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3089e3c71f9b4f048d5310134494f577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fc583acfc44906883b70de00e49d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# build bert_base model\n",
    "bert_model = SentenceTransformer(\"bert-base-nli-mean-tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "afe6852b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 768)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert job title into BERT embedded vectors\n",
    "bert_job_title_embeddings =bert_model.encode(list(df.job_title))\n",
    "bert_job_title_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b538512f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert search phrase into a bert embedded vector\n",
    "bert_search_phrase_embeddings = bert_model.encode(phrases.phrase[0])\n",
    "bert_search_phrase_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2ed8aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between job title and search phrase vectors\n",
    "bert_cosine_similarity= []\n",
    "for i in range(len(df)):\n",
    "    cos_sim = 1-cosine(bert_job_title_embeddings[i], bert_search_phrase_embeddings)\n",
    "    bert_cosine_similarity.append(cos_sim)\n",
    "    \n",
    "\n",
    "# add bert cosine_simirality column in th dataframe\n",
    "df[\"BERT_model_fit_score\"] =bert_cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "acdea4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>TF-IDF_fit_score</th>\n",
       "      <th>GloVe_fit_score</th>\n",
       "      <th>GoogleNews_fit_score</th>\n",
       "      <th>BERT_model_fit_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>aspiring human resource specialist</td>\n",
       "      <td>greater new york city area</td>\n",
       "      <td>1</td>\n",
       "      <td>0.679890</td>\n",
       "      <td>0.969614</td>\n",
       "      <td>0.912262</td>\n",
       "      <td>0.955137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aspiring human resource professional</td>\n",
       "      <td>raleigh durham  north carolina area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.781184</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>0.950395</td>\n",
       "      <td>0.948828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>97</td>\n",
       "      <td>aspiring human resource professional</td>\n",
       "      <td>kokomo  indiana area</td>\n",
       "      <td>71</td>\n",
       "      <td>0.781184</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>0.950395</td>\n",
       "      <td>0.948828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>82</td>\n",
       "      <td>aspiring human resource professional  energeti...</td>\n",
       "      <td>austin  texas area</td>\n",
       "      <td>174</td>\n",
       "      <td>0.379605</td>\n",
       "      <td>0.895589</td>\n",
       "      <td>0.827266</td>\n",
       "      <td>0.867910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>99</td>\n",
       "      <td>seeking human resource position</td>\n",
       "      <td>las vegas  nevada area</td>\n",
       "      <td>48</td>\n",
       "      <td>0.289466</td>\n",
       "      <td>0.869983</td>\n",
       "      <td>0.728513</td>\n",
       "      <td>0.849293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "5    6                 aspiring human resource specialist   \n",
       "2    3               aspiring human resource professional   \n",
       "45  97               aspiring human resource professional   \n",
       "30  82  aspiring human resource professional  energeti...   \n",
       "47  99                    seeking human resource position   \n",
       "\n",
       "                               location connection  TF-IDF_fit_score  \\\n",
       "5            greater new york city area          1          0.679890   \n",
       "2   raleigh durham  north carolina area         44          0.781184   \n",
       "45                 kokomo  indiana area         71          0.781184   \n",
       "30                   austin  texas area        174          0.379605   \n",
       "47               las vegas  nevada area         48          0.289466   \n",
       "\n",
       "    GloVe_fit_score  GoogleNews_fit_score  BERT_model_fit_score  \n",
       "5          0.969614              0.912262              0.955137  \n",
       "2          0.958512              0.950395              0.948828  \n",
       "45         0.958512              0.950395              0.948828  \n",
       "30         0.895589              0.827266              0.867910  \n",
       "47         0.869983              0.728513              0.849293  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"BERT_model_fit_score\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5747ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>TF-IDF_fit_score</th>\n",
       "      <th>GloVe_fit_score</th>\n",
       "      <th>GoogleNews_fit_score</th>\n",
       "      <th>BERT_model_fit_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>96</td>\n",
       "      <td>student indiana university kokomo  business ma...</td>\n",
       "      <td>lafayette  indiana</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517594</td>\n",
       "      <td>0.314945</td>\n",
       "      <td>0.230208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>102</td>\n",
       "      <td>business intelligence analytics not tech</td>\n",
       "      <td>greater new york city area</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662951</td>\n",
       "      <td>0.344934</td>\n",
       "      <td>0.198931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>93</td>\n",
       "      <td>admission representative community medical cen...</td>\n",
       "      <td>long beach  california</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.262623</td>\n",
       "      <td>0.181031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>85</td>\n",
       "      <td>rrp brand portfolio executive not tech japan t...</td>\n",
       "      <td>greater philadelphia area</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.579212</td>\n",
       "      <td>0.271064</td>\n",
       "      <td>0.147233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>87</td>\n",
       "      <td>bachelor science biology victoria university w...</td>\n",
       "      <td>baltimore  maryland</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518551</td>\n",
       "      <td>0.277453</td>\n",
       "      <td>0.136410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                          job_title  \\\n",
       "44   96  student indiana university kokomo  business ma...   \n",
       "50  102           business intelligence analytics not tech   \n",
       "41   93  admission representative community medical cen...   \n",
       "33   85  rrp brand portfolio executive not tech japan t...   \n",
       "35   87  bachelor science biology victoria university w...   \n",
       "\n",
       "                      location connection  TF-IDF_fit_score  GloVe_fit_score  \\\n",
       "44          lafayette  indiana         19               0.0         0.517594   \n",
       "50  greater new york city area         49               0.0         0.662951   \n",
       "41      long beach  california          9               0.0         0.664062   \n",
       "33   greater philadelphia area      500                 0.0         0.579212   \n",
       "35         baltimore  maryland         40               0.0         0.518551   \n",
       "\n",
       "    GoogleNews_fit_score  BERT_model_fit_score  \n",
       "44              0.314945              0.230208  \n",
       "50              0.344934              0.198931  \n",
       "41              0.262623              0.181031  \n",
       "33              0.271064              0.147233  \n",
       "35              0.277453              0.136410  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"BERT_model_fit_score\", ascending=False).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7768e85",
   "metadata": {},
   "source": [
    "**Among all of the models, the BERT model gives us a high score for the top rows and a low one for unrelated titles.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057cecd",
   "metadata": {},
   "source": [
    "## Learning to Rank (LTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98e88d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>TF-IDF_fit_score</th>\n",
       "      <th>GloVe_fit_score</th>\n",
       "      <th>GoogleNews_fit_score</th>\n",
       "      <th>BERT_model_fit_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ct  bauer college business graduate magna cum...</td>\n",
       "      <td>houston  texas</td>\n",
       "      <td>85</td>\n",
       "      <td>0.254004</td>\n",
       "      <td>0.627218</td>\n",
       "      <td>0.592438</td>\n",
       "      <td>0.557126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>native english teacher tech english program korea</td>\n",
       "      <td>kanada</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650306</td>\n",
       "      <td>0.283308</td>\n",
       "      <td>0.408490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aspiring human resource professional</td>\n",
       "      <td>raleigh durham  north carolina area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.781184</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>0.950395</td>\n",
       "      <td>0.948828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>people development coordinator not tech</td>\n",
       "      <td>denton  texas</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.734886</td>\n",
       "      <td>0.358650</td>\n",
       "      <td>0.318839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "      <td>i̇zmir  türkiye</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450873</td>\n",
       "      <td>0.206563</td>\n",
       "      <td>0.461810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1   ct  bauer college business graduate magna cum...   \n",
       "1   2  native english teacher tech english program korea   \n",
       "2   3               aspiring human resource professional   \n",
       "3   4            people development coordinator not tech   \n",
       "4   5       advisory board member celal bayar university   \n",
       "\n",
       "                              location connection  TF-IDF_fit_score  \\\n",
       "0                       houston  texas         85          0.254004   \n",
       "1                               kanada      500            0.000000   \n",
       "2  raleigh durham  north carolina area         44          0.781184   \n",
       "3                        denton  texas      500            0.000000   \n",
       "4                      i̇zmir  türkiye      500            0.000000   \n",
       "\n",
       "   GloVe_fit_score  GoogleNews_fit_score  BERT_model_fit_score  \n",
       "0         0.627218              0.592438              0.557126  \n",
       "1         0.650306              0.283308              0.408490  \n",
       "2         0.958512              0.950395              0.948828  \n",
       "3         0.734886              0.358650              0.318839  \n",
       "4         0.450873              0.206563              0.461810  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b3829903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to star any candidates? Enter 'Yes' or 'No': yes\n",
      "Enter ids of candidates you want to star (separated by space) : 8\n"
     ]
    }
   ],
   "source": [
    "star_candidate=input(\"Do you want to star any candidates? Enter 'Yes' or 'No': \")\n",
    "\n",
    "starred= []\n",
    "if star_candidate.lower()==\"yes\":\n",
    "    starred=[int(item) for item in input(\"Enter ids of candidates you want to star (separated by space) : \").split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8cbf71fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>TF-IDF_fit_score</th>\n",
       "      <th>GloVe_fit_score</th>\n",
       "      <th>GoogleNews_fit_score</th>\n",
       "      <th>BERT_model_fit_score</th>\n",
       "      <th>starred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ct  bauer college business graduate magna cum...</td>\n",
       "      <td>houston  texas</td>\n",
       "      <td>85</td>\n",
       "      <td>0.254004</td>\n",
       "      <td>0.627218</td>\n",
       "      <td>0.592438</td>\n",
       "      <td>0.557126</td>\n",
       "      <td>0.557126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>native english teacher tech english program korea</td>\n",
       "      <td>kanada</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650306</td>\n",
       "      <td>0.283308</td>\n",
       "      <td>0.408490</td>\n",
       "      <td>0.408490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aspiring human resource professional</td>\n",
       "      <td>raleigh durham  north carolina area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.781184</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>0.950395</td>\n",
       "      <td>0.948828</td>\n",
       "      <td>0.948828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>people development coordinator not tech</td>\n",
       "      <td>denton  texas</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.734886</td>\n",
       "      <td>0.358650</td>\n",
       "      <td>0.318839</td>\n",
       "      <td>0.318839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "      <td>i̇zmir  türkiye</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450873</td>\n",
       "      <td>0.206563</td>\n",
       "      <td>0.461810</td>\n",
       "      <td>0.461810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1   ct  bauer college business graduate magna cum...   \n",
       "1   2  native english teacher tech english program korea   \n",
       "2   3               aspiring human resource professional   \n",
       "3   4            people development coordinator not tech   \n",
       "4   5       advisory board member celal bayar university   \n",
       "\n",
       "                              location connection  TF-IDF_fit_score  \\\n",
       "0                       houston  texas         85          0.254004   \n",
       "1                               kanada      500            0.000000   \n",
       "2  raleigh durham  north carolina area         44          0.781184   \n",
       "3                        denton  texas      500            0.000000   \n",
       "4                      i̇zmir  türkiye      500            0.000000   \n",
       "\n",
       "   GloVe_fit_score  GoogleNews_fit_score  BERT_model_fit_score  starred_score  \n",
       "0         0.627218              0.592438              0.557126       0.557126  \n",
       "1         0.650306              0.283308              0.408490       0.408490  \n",
       "2         0.958512              0.950395              0.948828       0.948828  \n",
       "3         0.734886              0.358650              0.318839       0.318839  \n",
       "4         0.450873              0.206563              0.461810       0.461810  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"starred_score\"] =df[\"BERT_model_fit_score\"]\n",
    "for id_num in starred:\n",
    "    df.loc[df['id'] == id_num, \"starred_score\"]=1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d087b6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x209dbe29930>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Set a seed value\n",
    "seed_value= 12321 \n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set `torch` pseudo-random generator at a fixed value\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c52b9cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_feature):\n",
    "        super(RankNet, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_feature, 512),         \n",
    "            nn.Dropout(0.5),                     \n",
    "            nn.LeakyReLU(0.2, inplace=True),     \n",
    "            nn.Linear(512, 256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        self.output_sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_1, input_2):\n",
    "        s1 = self.model(input_1)\n",
    "        s2 = self.model(input_2)\n",
    "        out = self.output_sig(s1-s2)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, input_):\n",
    "        s = self.model(input_)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7acd3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row_1 = df.sample(n=100, replace=True)\n",
    "random_row_2 =df.sample(n=100, replace=True)\n",
    "job_title_list_ranknet1 = list(random_row_1[\"job_title\"])\n",
    "job_title_list_ranknet2 = list(random_row_2[\"job_title\"])\n",
    "doc_1 =bert_model.encode(job_title_list_ranknet1)\n",
    "doc_2 =bert_model.encode(job_title_list_ranknet2)\n",
    "doc_1 =torch.from_numpy(doc_1).float()\n",
    "doc_2 = torch.from_numpy(doc_2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "03474898",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = list(random_row_1['starred_score'])\n",
    "y_2 = list(random_row_2['starred_score'])\n",
    "y = torch.tensor([1.0 if y1_i>y2_i else 0.5 if y1_i==y2_i else 0.0 for y1_i, y2_i in zip(y_1, y_2)]).float()\n",
    "\n",
    "y = y.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "04eb4dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(optim, lr_list, epoch, patience):\n",
    "    # track the training loss as the model trains\n",
    "    losses= []\n",
    "    \n",
    "    model =RankNet(num_feature=768)\n",
    "    loss_fun= torch.nn.BCELoss()\n",
    "    \n",
    "    for lr in lr_list:\n",
    "        if optim ==\"SGD\":\n",
    "            optimizer =torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "        elif optim==\"Adam\":\n",
    "            optimizer =torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        print(\"lr: \", lr, \"optimizer: \", optim)\n",
    "        epoch = epoch\n",
    "        train_losses  =[]\n",
    "        valid_losses = []\n",
    "        \n",
    "        for i in range(1, epoch+1):\n",
    "            model.zero_grad()\n",
    "            y_pred =model(doc_1, doc_2)\n",
    "            loss=loss_fun(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            if i %100 ==0:\n",
    "                print(\"Epoch{}, loss: {}\".format(i, loss.item()))\n",
    "                \n",
    "        print(\"=\"*100)\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7f8dd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.1 optimizer:  SGD\n",
      "Epoch100, loss: 0.5080745220184326\n",
      "Epoch200, loss: 0.4885023832321167\n",
      "Epoch300, loss: 0.4944716691970825\n",
      "Epoch400, loss: 0.4932858943939209\n",
      "Epoch500, loss: 0.4906902313232422\n",
      "Epoch600, loss: 0.49168312549591064\n",
      "Epoch700, loss: 0.49649161100387573\n",
      "Epoch800, loss: 0.48243194818496704\n",
      "Epoch900, loss: 0.48973309993743896\n",
      "Epoch1000, loss: 0.4859377145767212\n",
      "====================================================================================================\n",
      "lr:  0.01 optimizer:  SGD\n",
      "Epoch100, loss: 0.4868333339691162\n",
      "Epoch200, loss: 0.4887847602367401\n",
      "Epoch300, loss: 0.48420047760009766\n",
      "Epoch400, loss: 0.4925222098827362\n",
      "Epoch500, loss: 0.48924899101257324\n",
      "Epoch600, loss: 0.48541712760925293\n",
      "Epoch700, loss: 0.48472148180007935\n",
      "Epoch800, loss: 0.487932026386261\n",
      "Epoch900, loss: 0.4922143816947937\n",
      "Epoch1000, loss: 0.48818713426589966\n",
      "====================================================================================================\n",
      "lr:  0.001 optimizer:  SGD\n",
      "Epoch100, loss: 0.4889654815196991\n",
      "Epoch200, loss: 0.48435497283935547\n",
      "Epoch300, loss: 0.4921264350414276\n",
      "Epoch400, loss: 0.48823028802871704\n",
      "Epoch500, loss: 0.48427486419677734\n",
      "Epoch600, loss: 0.4934704899787903\n",
      "Epoch700, loss: 0.4887162148952484\n",
      "Epoch800, loss: 0.49290740489959717\n",
      "Epoch900, loss: 0.49238044023513794\n",
      "Epoch1000, loss: 0.4935777187347412\n",
      "====================================================================================================\n",
      "lr:  0.0001 optimizer:  SGD\n",
      "Epoch100, loss: 0.4853920042514801\n",
      "Epoch200, loss: 0.49601009488105774\n",
      "Epoch300, loss: 0.48672181367874146\n",
      "Epoch400, loss: 0.48943182826042175\n",
      "Epoch500, loss: 0.48922309279441833\n",
      "Epoch600, loss: 0.4913448989391327\n",
      "Epoch700, loss: 0.4908791482448578\n",
      "Epoch800, loss: 0.4906507730484009\n",
      "Epoch900, loss: 0.4883420169353485\n",
      "Epoch1000, loss: 0.4919791519641876\n",
      "====================================================================================================\n",
      "lr:  1e-05 optimizer:  SGD\n",
      "Epoch100, loss: 0.48656487464904785\n",
      "Epoch200, loss: 0.48586052656173706\n",
      "Epoch300, loss: 0.4937487542629242\n",
      "Epoch400, loss: 0.4869403839111328\n",
      "Epoch500, loss: 0.4936152994632721\n",
      "Epoch600, loss: 0.4875258505344391\n",
      "Epoch700, loss: 0.4907640814781189\n",
      "Epoch800, loss: 0.49073028564453125\n",
      "Epoch900, loss: 0.4890245199203491\n",
      "Epoch1000, loss: 0.4873560070991516\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model, train_loss= train_model(optim=\"SGD\", \n",
    "                              lr_list=[0.1,0.01,0.001,0.0001,0.00001],\n",
    "                              epoch=1000,\n",
    "                              patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d4ef963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.01 optimizer:  SGD\n",
      "Epoch100, loss: 0.5159167647361755\n",
      "Epoch200, loss: 0.5027689933776855\n",
      "Epoch300, loss: 0.4991055727005005\n",
      "Epoch400, loss: 0.4962245523929596\n",
      "Epoch500, loss: 0.4974112808704376\n",
      "Epoch600, loss: 0.4880216717720032\n",
      "Epoch700, loss: 0.4875315725803375\n",
      "Epoch800, loss: 0.4951327443122864\n",
      "Epoch900, loss: 0.488869845867157\n",
      "Epoch1000, loss: 0.49069511890411377\n",
      "Epoch1100, loss: 0.4848949909210205\n",
      "Epoch1200, loss: 0.4906507134437561\n",
      "Epoch1300, loss: 0.4879225194454193\n",
      "Epoch1400, loss: 0.49273258447647095\n",
      "Epoch1500, loss: 0.4900534749031067\n",
      "Epoch1600, loss: 0.4932117462158203\n",
      "Epoch1700, loss: 0.49330803751945496\n",
      "Epoch1800, loss: 0.48913443088531494\n",
      "Epoch1900, loss: 0.48739299178123474\n",
      "Epoch2000, loss: 0.4885859787464142\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model, train_loss =train_model(optim=\"SGD\", lr_list=[0.01],\n",
    "                              epoch=2000,\n",
    "                              patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "206adc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.1 optimizer:  Adam\n",
      "Epoch100, loss: 0.7025609016418457\n",
      "Epoch200, loss: 0.6931471228599548\n",
      "Epoch300, loss: 0.6893482804298401\n",
      "Epoch400, loss: 0.6931471228599548\n",
      "Epoch500, loss: 0.6931471228599548\n",
      "Epoch600, loss: 0.6893482804298401\n",
      "Epoch700, loss: 0.6931471228599548\n",
      "Epoch800, loss: 0.6931471228599548\n",
      "Epoch900, loss: 0.6931471228599548\n",
      "Epoch1000, loss: 0.6931471228599548\n",
      "====================================================================================================\n",
      "lr:  0.01 optimizer:  Adam\n",
      "Epoch100, loss: 0.6931471228599548\n",
      "Epoch200, loss: 0.6931471228599548\n",
      "Epoch300, loss: 0.6931471228599548\n",
      "Epoch400, loss: 0.6893482804298401\n",
      "Epoch500, loss: 0.6893482804298401\n",
      "Epoch600, loss: 0.6893482804298401\n",
      "Epoch700, loss: 0.6931471228599548\n",
      "Epoch800, loss: 0.6931471228599548\n",
      "Epoch900, loss: 0.6931471228599548\n",
      "Epoch1000, loss: 0.6931471228599548\n",
      "====================================================================================================\n",
      "lr:  0.001 optimizer:  Adam\n",
      "Epoch100, loss: 0.6931471228599548\n",
      "Epoch200, loss: 0.6931471228599548\n",
      "Epoch300, loss: 0.6893482208251953\n",
      "Epoch400, loss: 0.6917506456375122\n",
      "Epoch500, loss: 0.6855493783950806\n",
      "Epoch600, loss: 0.6893482208251953\n",
      "Epoch700, loss: 0.6893482804298401\n",
      "Epoch800, loss: 0.6855494976043701\n",
      "Epoch900, loss: 0.6779517531394958\n",
      "Epoch1000, loss: 0.6713597774505615\n",
      "====================================================================================================\n",
      "lr:  0.0001 optimizer:  Adam\n",
      "Epoch100, loss: 0.6675609350204468\n",
      "Epoch200, loss: 0.6613597869873047\n",
      "Epoch300, loss: 0.6599632501602173\n",
      "Epoch400, loss: 0.6499632000923157\n",
      "Epoch500, loss: 0.6513597965240479\n",
      "Epoch600, loss: 0.6713597774505615\n",
      "Epoch700, loss: 0.6627563238143921\n",
      "Epoch800, loss: 0.6751586198806763\n",
      "Epoch900, loss: 0.6575608849525452\n",
      "Epoch1000, loss: 0.6599632501602173\n",
      "====================================================================================================\n",
      "lr:  1e-05 optimizer:  Adam\n",
      "Epoch100, loss: 0.678957462310791\n",
      "Epoch200, loss: 0.6727563738822937\n",
      "Epoch300, loss: 0.6613597869873047\n",
      "Epoch400, loss: 0.6475608944892883\n",
      "Epoch500, loss: 0.6575609445571899\n",
      "Epoch600, loss: 0.6475608944892883\n",
      "Epoch700, loss: 0.6765551567077637\n",
      "Epoch800, loss: 0.6713597774505615\n",
      "Epoch900, loss: 0.6627563238143921\n",
      "Epoch1000, loss: 0.6575608849525452\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model, train_loss =train_model(optim=\"Adam\",\n",
    "                              lr_list=[0.1,0.01,0.001,0.0001,0.00001],\n",
    "                              epoch=1000,\n",
    "                              patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "22f6c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_feature):\n",
    "        super(RankNet, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_feature, num_feature*2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(num_feature*2, num_feature *4),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(num_feature*4,1),\n",
    "            nn.Sigmoid())\n",
    "        self.output_sig =nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_1, input_2):\n",
    "        s1 =self.model(input_1)\n",
    "        s2 =self.model(input_2)\n",
    "        out =self.output_sig(s1-s2)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, input_):\n",
    "        s = self.model(input_)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d09456f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.01 optimizer:  SGD\n",
      "Epoch100, loss: 0.5054026246070862\n",
      "Epoch200, loss: 0.4938727617263794\n",
      "Epoch300, loss: 0.49243098497390747\n",
      "Epoch400, loss: 0.49046391248703003\n",
      "Epoch500, loss: 0.4883538782596588\n",
      "Epoch600, loss: 0.4897862374782562\n",
      "Epoch700, loss: 0.487813264131546\n",
      "Epoch800, loss: 0.48874035477638245\n",
      "Epoch900, loss: 0.4877861440181732\n",
      "Epoch1000, loss: 0.4909791052341461\n",
      "Epoch1100, loss: 0.4902816116809845\n",
      "Epoch1200, loss: 0.48854759335517883\n",
      "Epoch1300, loss: 0.49258536100387573\n",
      "Epoch1400, loss: 0.48743969202041626\n",
      "Epoch1500, loss: 0.4873252809047699\n",
      "Epoch1600, loss: 0.48870840668678284\n",
      "Epoch1700, loss: 0.4916936755180359\n",
      "Epoch1800, loss: 0.48628273606300354\n",
      "Epoch1900, loss: 0.4872210621833801\n",
      "Epoch2000, loss: 0.48841214179992676\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model, train_loss =train_model(optim=\"SGD\", \n",
    "                              lr_list=[0.01],\n",
    "                              epoch=2000,\n",
    "                              patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1a53e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score = []\n",
    "for i in range(len(df)):\n",
    "    embedding =bert_model.encode([df[\"job_title\"][i]])\n",
    "    embedding_tensor = torch.from_numpy(embedding).float()\n",
    "    pred = round(model.predict(embedding_tensor).detach().numpy().sum(),2)\n",
    "    pred_score.append(pred)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "84abbee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>TF-IDF_fit_score</th>\n",
       "      <th>GloVe_fit_score</th>\n",
       "      <th>GoogleNews_fit_score</th>\n",
       "      <th>BERT_model_fit_score</th>\n",
       "      <th>starred_score</th>\n",
       "      <th>RankNet_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>104</td>\n",
       "      <td>director administration excellence logtechng</td>\n",
       "      <td>katy  texas</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.665444</td>\n",
       "      <td>0.191680</td>\n",
       "      <td>0.621203</td>\n",
       "      <td>0.621203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>74</td>\n",
       "      <td>human resource professional</td>\n",
       "      <td>greater boston area</td>\n",
       "      <td>16</td>\n",
       "      <td>0.421758</td>\n",
       "      <td>0.933199</td>\n",
       "      <td>0.874494</td>\n",
       "      <td>0.809261</td>\n",
       "      <td>0.809261</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>76</td>\n",
       "      <td>aspiring human resource professional  passiona...</td>\n",
       "      <td>new york  new york</td>\n",
       "      <td>212</td>\n",
       "      <td>0.259969</td>\n",
       "      <td>0.917865</td>\n",
       "      <td>0.741262</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>79</td>\n",
       "      <td>liberal art major  aspiring human resource ana...</td>\n",
       "      <td>baton rouge  louisiana area</td>\n",
       "      <td>7</td>\n",
       "      <td>0.354417</td>\n",
       "      <td>0.850251</td>\n",
       "      <td>0.731783</td>\n",
       "      <td>0.557962</td>\n",
       "      <td>0.557962</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>82</td>\n",
       "      <td>aspiring human resource professional  energeti...</td>\n",
       "      <td>austin  texas area</td>\n",
       "      <td>174</td>\n",
       "      <td>0.379605</td>\n",
       "      <td>0.895589</td>\n",
       "      <td>0.827266</td>\n",
       "      <td>0.867910</td>\n",
       "      <td>0.867910</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                          job_title  \\\n",
       "52  104       director administration excellence logtechng   \n",
       "22   74                        human resource professional   \n",
       "24   76  aspiring human resource professional  passiona...   \n",
       "27   79  liberal art major  aspiring human resource ana...   \n",
       "30   82  aspiring human resource professional  energeti...   \n",
       "\n",
       "                       location connection  TF-IDF_fit_score  GloVe_fit_score  \\\n",
       "52                  katy  texas      500            0.000000         0.665444   \n",
       "22          greater boston area         16          0.421758         0.933199   \n",
       "24           new york  new york        212          0.259969         0.917865   \n",
       "27  baton rouge  louisiana area          7          0.354417         0.850251   \n",
       "30           austin  texas area        174          0.379605         0.895589   \n",
       "\n",
       "    GoogleNews_fit_score  BERT_model_fit_score  starred_score  RankNet_score  \n",
       "52              0.191680              0.621203       0.621203            1.0  \n",
       "22              0.874494              0.809261       0.809261            1.0  \n",
       "24              0.741262              0.765864       0.765864            1.0  \n",
       "27              0.731783              0.557962       0.557962            1.0  \n",
       "30              0.827266              0.867910       0.867910            1.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"RankNet_score\"] =pred_score\n",
    "df.sort_values(by=\"RankNet_score\", ascending =False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5283b6",
   "metadata": {},
   "source": [
    "## CONCLUSION\n",
    "\n",
    "\n",
    "\n",
    "`BERT` Model was one of the best model to find similarity betwwen our data and the targeted phrase. As for the Ranking Model I ran `RankNet` model on the data and the best Loss score was 48%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
